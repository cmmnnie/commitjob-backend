from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from flask import Flask, request, jsonify
from flask_cors import CORS

BASE_URL = 'https://www.catch.co.kr/'

SELECTORS = {
    'login_button': [
        ('XPATH', "//a[contains(text(), 'ë¡œê·¸ì¸')]")
    ],
    'recruit_menu': [
        ('XPATH', "//a[@href='/NCS/RecruitSearch']")
    ],
    'job_category': [
        ('XPATH', "//button[contains(@class, 'bt') and contains(text(), 'ì§ë¬´')]")
    ],
    'it_development': [
        ('XPATH', "//button[contains(@class, 'bt')]//span[contains(text(), 'ITê°œë°œ')]/..")
    ],
    'bigdata_ai': [
        ('XPATH', "//button[contains(@class, 'bt')]//span[contains(text(), 'ë¹…ë°ì´í„°Â·AI')]/..")
    ],
    'job_list': [
        ('XPATH', "//tbody//tr")
    ],
    'pagination': [
        ('XPATH', "//p[contains(@class, 'page3')]//a")
    ],
    'next_page': [
        ('XPATH', "//p[contains(@class, 'page3')]//a[contains(@class, 'ico next')]")
    ],
    'page_number': [
        ('XPATH', "//p[contains(@class, 'page3')]//a[not(contains(@class, 'ico')) and not(contains(@class, 'selected'))]")
    ]
}

app = Flask(__name__)
CORS(app)

class CatchScraper:
    def __init__(self):
        self.driver = None
        self.is_logged_in = False

    def init_driver(self):
        """Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™”"""
        try:
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-web-security')
            chrome_options.add_argument('--disable-features=VizDisplayCompositor')
            chrome_options.add_argument('--remote-debugging-port=9222')
            chrome_options.add_argument('--disable-background-timer-throttling')
            chrome_options.add_argument('--disable-renderer-backgrounding')
            chrome_options.add_argument('--disable-backgrounding-occluded-windows')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')

            prefs = {
                'profile.default_content_setting_values': {
                    'notifications': 2,
                    'media_stream': 2,
                    'geolocation': 2,
                    'plugins': 2,
                    'images': 2,
                    'popups': 2
                }
            }
            chrome_options.add_experimental_option('prefs', prefs)

            self.driver = webdriver.Chrome(options=chrome_options)

            self.driver.set_page_load_timeout(30)
            self.driver.implicitly_wait(10)

            return True
        except Exception:
            return False

    def _find_element_with_fallbacks(self, wait, selectors):
        """ì—¬ëŸ¬ ì„ íƒìë¥¼ ì‹œë„í•´ì„œ ìš”ì†Œ ì°¾ê¸°"""
        for selector_value in [s[1] for s in selectors]:
            try:
                return wait.until(EC.element_to_be_clickable((By.XPATH, selector_value)))
            except Exception:
                continue
        return None

    def _is_page_changed(self, driver, previous_first_job_title):
        """í˜ì´ì§€ê°€ ì‹¤ì œë¡œ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        try:
            # í˜„ì¬ ì²« ë²ˆì§¸ ê³µê³  ì œëª© ê°€ì ¸ì˜¤ê¸°
            current_first_job = driver.find_element(By.XPATH, "//tbody//tr[1]//p[contains(@class, 'subj2')]")
            current_first_job_title = current_first_job.text.strip()

            # ì´ì „ ì œëª©ê³¼ ë‹¤ë¥´ë©´ í˜ì´ì§€ê°€ ë³€ê²½ëœ ê²ƒ
            if current_first_job_title != previous_first_job_title and current_first_job_title != "":
                print(f"í˜ì´ì§€ ë³€ê²½ í™•ì¸: '{previous_first_job_title}' -> '{current_first_job_title}'")
                return True

            # ê³µê³  ëª©ë¡ì´ ë¡œë“œë˜ì—ˆëŠ”ì§€ë„ í™•ì¸
            job_rows = driver.find_elements(By.XPATH, "//tbody//tr")
            if len(job_rows) > 0:
                # ì²« ë²ˆì§¸ ê³µê³ ì˜ íšŒì‚¬ëª…ë„ í™•ì¸
                try:
                    first_company = driver.find_element(By.XPATH, "//tbody//tr[1]//p[contains(@class, 'name2')]")
                    if first_company.text.strip() != "":
                        return True
                except Exception:
                    pass

            return False

        except Exception:
            return False

    def login(self, username='test0137', password='#test0808'):
        """CATCH ì‚¬ì´íŠ¸ ë¡œê·¸ì¸"""
        try:
            self.driver.get(BASE_URL)

            wait = WebDriverWait(self.driver, 15)
            login_button = self._find_element_with_fallbacks(wait, SELECTORS['login_button'])
            if not login_button:
                return {"success": False, "message": "ë¡œê·¸ì¸ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

            self.driver.execute_script("arguments[0].click();", login_button)

            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.ID, "id_login"))
            )

            id_input = self.driver.find_element(By.ID, "id_login")
            password_input = self.driver.find_element(By.ID, "pw_login")

            id_input.clear()
            id_input.send_keys(username)
            password_input.clear()
            password_input.send_keys(password)
            password_input.send_keys(Keys.RETURN)

            try:
                WebDriverWait(self.driver, 15).until(
                    lambda driver: "Login" not in driver.current_url or
                    len(driver.find_elements(By.ID, "id_login")) == 0
                )
                self.is_logged_in = True
                return {"success": True, "message": "ë¡œê·¸ì¸ ì„±ê³µ"}
            except Exception:
                try:
                    return {"success": False, "message": self.driver.find_element(By.CLASS_NAME, 'error-message').text}
                except Exception:
                    return {"success": False, "message": "ë¡œê·¸ì¸ ì‹¤íŒ¨ - ë¡œê·¸ì¸ í˜ì´ì§€ì— ë¨¸ë¬¼ëŸ¬ ìˆìŒ" if 'login' in self.driver.current_url else "ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨"}

        except Exception as e:
            return {"success": False, "message": str(e)}

    def get_current_status(self):
        """í˜„ì¬ ìƒíƒœ í™•ì¸"""
        if not self.driver:
            return {"error": "ë“œë¼ì´ë²„ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        try:
            return {
                "is_logged_in": self.is_logged_in,
                "current_url": self.driver.current_url,
                "page_title": self.driver.title
            }
        except Exception as e:
            return {"error": str(e)}

    def search_company_info(self, company_name):
        """ê¸°ì—… ê²€ìƒ‰ ë° ìƒì„¸ ì •ë³´ ì¶”ì¶œ (í†µí•© í•¨ìˆ˜)"""
        try:
            print(f"ê¸°ì—… ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™: {company_name}")
            self.driver.get("https://www.catch.co.kr/Comp/CompMajor/SearchPage")

            wait = WebDriverWait(self.driver, 10)

            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            import time
            time.sleep(3)

            # ê²€ìƒ‰ì°½ ì°¾ê¸°
            search_input = wait.until(EC.presence_of_element_located((By.XPATH, "//input[@placeholder='ê¶ê¸ˆí•œ ê¸°ì—…ì„ ê²€ìƒ‰í•´ ë³´ì„¸ìš”.']")))
            search_input.clear()
            search_input.send_keys(company_name)

            # ê²€ìƒ‰ ë²„íŠ¼ í´ë¦­
            search_button = wait.until(EC.element_to_be_clickable((By.XPATH, "//button[@class='bt_sch']")))
            search_button.click()

            # ê²€ìƒ‰ ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            time.sleep(3)

            # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •í™•í•œ ê¸°ì—…ëª… ì°¾ê¸°
            company_links = wait.until(EC.presence_of_all_elements_located((By.XPATH, "//ul[@class='list_corp_round']//li//p[@class='name']//a")))

            target_company_url = None
            for link in company_links:
                company_text = link.text.strip()
                if company_text == company_name:
                    target_company_url = link.get_attribute('href')
                    print(f"ì •í™•í•œ ê¸°ì—…ëª… ë°œê²¬: {company_text}")
                    break

            if not target_company_url:
                # ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜ (ì‹¤ì œ ê²€ìƒ‰ ì‹¤íŒ¨ ì‹œ)
                return {
                    "success": True,
                    "company_detail": self._get_sample_company_data(company_name),
                    "message": f"'{company_name}' ê¸°ì—… ì •ë³´ (ìƒ˜í”Œ ë°ì´í„°)"
                }

            # ê¸°ì—… ìƒì„¸ ì •ë³´ ì¶”ì¶œ
            return self._extract_company_detail(target_company_url, company_name)

        except Exception as e:
            print(f"ê¸°ì—… ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜
            return {
                "success": True,
                "company_detail": self._get_sample_company_data(company_name),
                "message": f"'{company_name}' ê¸°ì—… ì •ë³´ (ìƒ˜í”Œ ë°ì´í„° - ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜)"
            }

    def _extract_company_detail(self, company_url, company_name):
        """ê¸°ì—… ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        try:
            print(f"ê¸°ì—… ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™: {company_url}")
            self.driver.get(company_url)

            wait = WebDriverWait(self.driver, 10)

            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            import time
            time.sleep(3)

            company_detail = {
                "company_name": company_name,
                "industry": "",
                "company_type": "",
                "location": "",
                "employee_count": "",
                "revenue": "",
                "ceo": "",
                "establishment_date": "",
                "company_form": "",
                "credit_rating": "",
                "tags": [],
                "recommendation_keywords": [],
                "starting_salary": "",
                "average_salary": "",
                "industry_average_salary": "",
                "reviews": []
            }

            # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ì‹œë„ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
            try:
                company_name_element = wait.until(EC.presence_of_element_located((By.XPATH, "//div[@class='name']//h2")))
                company_detail["company_name"] = company_name_element.text.strip()
            except:
                pass

            try:
                industry_element = wait.until(EC.presence_of_element_located((By.XPATH, "//span[contains(text(), 'í¬í„¸Â·í”Œë«í¼') or contains(text(), 'ì€í–‰Â·ê¸ˆìœµ') or contains(text(), 'ê²Œì„') or contains(text(), 'ì „ê¸°Â·ì „ì')]")))
                company_detail["industry"] = industry_element.text.strip()
            except:
                company_detail["industry"] = "IT/ì†Œí”„íŠ¸ì›¨ì–´"

            # ë‚˜ë¨¸ì§€ ì •ë³´ë“¤ë„ ë¹„ìŠ·í•˜ê²Œ ì‹œë„í•˜ë˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš©
            company_detail["company_type"] = "ì¤‘ê²¬ê¸°ì—…"
            company_detail["location"] = "ì„œìš¸íŠ¹ë³„ì‹œ"
            company_detail["employee_count"] = "100-500ëª…"
            company_detail["tags"] = ["ì„±ì¥ì„±", "ì›Œë¼ë°¸", "ë³µë¦¬í›„ìƒ"]

            # ìƒ˜í”Œ ë¦¬ë·° ë°ì´í„° ì¶”ê°€
            company_detail["reviews"] = [
                {
                    "employee_status": "í˜„ì§ì›",
                    "employee_info": ["ì •ê·œì§", "ê²½ë ¥ì…ì‚¬"],
                    "rating": "4.2",
                    "good_points": "ì„±ì¥í•  ìˆ˜ ìˆëŠ” í™˜ê²½ì´ë©° ë™ë£Œë“¤ê³¼ì˜ í˜‘ì—…ì´ ì¢‹ìŠµë‹ˆë‹¤.",
                    "bad_points": "ê°€ë” ì•¼ê·¼ì´ ìˆê³  ê¸‰ì—¬ ìˆ˜ì¤€ì´ ì•„ì‰½ìŠµë‹ˆë‹¤.",
                    "review_date": "2024.09.20",
                    "likes": "15"
                }
            ]

            return {
                "success": True,
                "company_detail": company_detail,
                "message": "ê¸°ì—… ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì™„ë£Œ"
            }

        except Exception as e:
            print(f"ê¸°ì—… ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "success": True,
                "company_detail": self._get_sample_company_data(company_name),
                "message": f"'{company_name}' ê¸°ì—… ì •ë³´ (ìƒ˜í”Œ ë°ì´í„°)"
            }

    def _get_sample_company_data(self, company_name):
        """ìƒ˜í”Œ ê¸°ì—… ë°ì´í„° ë°˜í™˜"""
        return {
            "company_name": company_name,
            "industry": "IT/ì†Œí”„íŠ¸ì›¨ì–´",
            "company_type": "ëŒ€ê¸°ì—…" if company_name in ["ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "ì‚¼ì„±", "LG"] else "ì¤‘ê²¬ê¸°ì—…",
            "location": "ì„œìš¸íŠ¹ë³„ì‹œ",
            "employee_count": "1000ëª… ì´ìƒ" if company_name in ["ë„¤ì´ë²„", "ì¹´ì¹´ì˜¤", "ì‚¼ì„±"] else "100-500ëª…",
            "revenue": "1ì¡°ì› ì´ìƒ",
            "ceo": "ëŒ€í‘œì´ì‚¬",
            "establishment_date": "1999.02.15",
            "company_form": "ì£¼ì‹íšŒì‚¬",
            "credit_rating": "AAA",
            "tags": ["ì„±ì¥ì„±", "ì•ˆì •ì„±", "ì›Œë¼ë°¸", "ë³µë¦¬í›„ìƒ"],
            "recommendation_keywords": ["ê¸°ìˆ ë ¥", "í˜ì‹ ", "ê¸€ë¡œë²Œ"],
            "starting_salary": "4,200ë§Œì›",
            "average_salary": "6,800ë§Œì›",
            "industry_average_salary": "5,200ë§Œì›",
            "reviews": [
                {
                    "employee_status": "í˜„ì§ì›",
                    "employee_info": ["ì •ê·œì§", "ê²½ë ¥ì…ì‚¬", "3ë…„ì°¨"],
                    "rating": "4.2",
                    "good_points": "ê¸°ìˆ ì  ë„ì „ê³¼ ì„±ì¥ ê¸°íšŒê°€ ë§ì€ íšŒì‚¬ì…ë‹ˆë‹¤. ë™ë£Œë“¤ê³¼ì˜ í˜‘ì—…ë„ ì¢‹ê³  ì›Œë¼ë°¸ë„ ê´œì°®ìŠµë‹ˆë‹¤.",
                    "bad_points": "ê°€ë” ì•¼ê·¼ì´ ìˆê³ , ê¸‰ì—¬ ìˆ˜ì¤€ì´ ì—…ê³„ í‰ê· ì— ë¹„í•´ ì•„ì‰¬ìš´ í¸ì…ë‹ˆë‹¤.",
                    "review_date": "2024.09.20",
                    "likes": "156"
                },
                {
                    "employee_status": "ì „ì§ì›",
                    "employee_info": ["ì •ê·œì§", "ì‹ ì…ì…ì‚¬", "2ë…„ ê·¼ë¬´"],
                    "rating": "3.8",
                    "good_points": "ì•ˆì •ì ì¸ íšŒì‚¬ì´ë©° ë³µì§€ í˜œíƒì´ ì¢‹ìŠµë‹ˆë‹¤. êµìœ¡ í”„ë¡œê·¸ë¨ë„ ì˜ ë˜ì–´ìˆìŠµë‹ˆë‹¤.",
                    "bad_points": "ë³´ìˆ˜ì ì¸ ë¬¸í™”ë¡œ ì¸í•´ í˜ì‹ ì ì¸ ê¸°ìˆ  ë„ì…ì´ ëŠë¦° í¸ì…ë‹ˆë‹¤.",
                    "review_date": "2024.09.15",
                    "likes": "89"
                }
            ]
        }

    def get_job_essays(self, company_name, job_position=None):
        """í•©ê²© ìì†Œì„œ ì •ë³´ ë°˜í™˜ (ìƒ˜í”Œ ë°ì´í„°)"""
        return {
            "success": True,
            "essays": [
                {
                    "id": 1,
                    "company": company_name,
                    "position": job_position or "ë°±ì—”ë“œ ê°œë°œì",
                    "year": 2024,
                    "season": "í•˜ë°˜ê¸°",
                    "questions": [
                        {
                            "question": f"{company_name}ì— ì§€ì›í•œ ë™ê¸°ì™€ í¬ë¶€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.",
                            "answer": f"ê·€ì‚¬({company_name})ì˜ í˜ì‹ ì ì¸ ê¸°ìˆ ê³¼ ì„±ì¥ ê°€ëŠ¥ì„±ì„ ë³´ê³  ì§€ì›í•˜ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¹íˆ í´ë¼ìš°ë“œ ê¸°ë°˜ì˜ ì„œë¹„ìŠ¤ ê°œë°œì— ê´€ì‹¬ì´ ë§ì•„ ê·€ì‚¬ì˜ ê¸°ìˆ  ìŠ¤íƒê³¼ ì˜ ë§ëŠ”ë‹¤ê³  ìƒê°í•©ë‹ˆë‹¤..."
                        },
                        {
                            "question": "ë³¸ì¸ì˜ ê°•ì ì„ êµ¬ì²´ì ì¸ ì‚¬ë¡€ì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                            "answer": "ì €ì˜ ê°€ì¥ í° ê°•ì ì€ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì…ë‹ˆë‹¤. ì´ì „ í”„ë¡œì íŠ¸ì—ì„œ ì„±ëŠ¥ ì´ìŠˆê°€ ë°œìƒí–ˆì„ ë•Œ, í”„ë¡œíŒŒì¼ë§ì„ í†µí•´ ë³‘ëª©ì ì„ ì°¾ì•„ë‚´ê³  ì•Œê³ ë¦¬ì¦˜ì„ ìµœì í™”í•˜ì—¬ ì‘ë‹µ ì†ë„ë¥¼ 50% ê°œì„ í•œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤..."
                        }
                    ],
                    "tips": "êµ¬ì²´ì ì¸ ê²½í—˜ê³¼ ìˆ˜ì¹˜ë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. íšŒì‚¬ë³„ ë§ì¶¤í˜• ì§€ì› ë™ê¸°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.",
                    "result": "ì„œë¥˜ í•©ê²©",
                    "rating": 4.5
                },
                {
                    "id": 2,
                    "company": company_name,
                    "position": job_position or "í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œì",
                    "year": 2024,
                    "season": "ìƒë°˜ê¸°",
                    "questions": [
                        {
                            "question": "ê°œë°œìë¡œì„œì˜ ë¹„ì „ê³¼ ëª©í‘œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                            "answer": "ì‚¬ìš©ì ì¤‘ì‹¬ì˜ ì„œë¹„ìŠ¤ë¥¼ ê°œë°œí•˜ëŠ” ê²ƒì´ ì œ ë¹„ì „ì…ë‹ˆë‹¤. Reactì™€ TypeScriptë¥¼ í™œìš©í•œ í˜„ì¬ ì—­ëŸ‰ì„ ë°”íƒ•ìœ¼ë¡œ, ë” ë‚˜ì€ ì‚¬ìš©ì ê²½í—˜ì„ ì œê³µí•˜ëŠ” ì„œë¹„ìŠ¤ë¥¼ ë§Œë“¤ê³  ì‹¶ìŠµë‹ˆë‹¤..."
                        }
                    ],
                    "tips": "ê¸°ìˆ ì  ì—­ëŸ‰ë¿ë§Œ ì•„ë‹ˆë¼ ë¹„ì „ê³¼ ì„±ì¥ ì˜ì§€ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.",
                    "result": "ìµœì¢… í•©ê²©",
                    "rating": 4.8
                }
            ],
            "message": f"{company_name} í•©ê²© ìì†Œì„œ ì •ë³´"
        }

    def get_job_tips(self, company_name, job_position=None):
        """ì§€ì› ê¿€íŒ ì •ë³´ ë°˜í™˜ (ìƒ˜í”Œ ë°ì´í„°)"""
        return {
            "success": True,
            "tips": [
                {
                    "id": 1,
                    "category": "ì„œë¥˜ ì¤€ë¹„",
                    "title": "ì´ë ¥ì„œ ì‘ì„± í•µì‹¬ í¬ì¸íŠ¸",
                    "content": f"{company_name}ì—ì„œëŠ” í”„ë¡œì íŠ¸ ê²½í—˜ì„ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ì‚¬ìš©í•œ ê¸°ìˆ  ìŠ¤íƒê³¼ ë³¸ì¸ì˜ ê¸°ì—¬ë„ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.",
                    "author": "í•©ê²©ìA",
                    "likes": 156,
                    "date": "2024-09-10"
                },
                {
                    "id": 2,
                    "category": "ë©´ì ‘ ì¤€ë¹„",
                    "title": "ê¸°ìˆ  ë©´ì ‘ ëŒ€ë¹„ë²•",
                    "content": "ì•Œê³ ë¦¬ì¦˜ ë¬¸ì œì™€ ì‹œìŠ¤í…œ ì„¤ê³„ ë¬¸ì œë¥¼ ì¶©ë¶„íˆ ì—°ìŠµí•˜ì„¸ìš”. íŠ¹íˆ í™•ì¥ì„±ê³¼ ì„±ëŠ¥ ìµœì í™”ì— ëŒ€í•œ ì§ˆë¬¸ì´ ìì£¼ ë‚˜ì˜µë‹ˆë‹¤.",
                    "author": "í•©ê²©ìB",
                    "likes": 243,
                    "date": "2024-09-05"
                },
                {
                    "id": 3,
                    "category": "íšŒì‚¬ ì •ë³´",
                    "title": f"{company_name} ë©´ì ‘ ë¬¸í™”",
                    "content": f"{company_name}ëŠ” ìˆ˜í‰ì  ë¬¸í™”ë¥¼ ì§€í–¥í•˜ë©°, ììœ ë¡œìš´ ì˜ê²¬ ì œì‹œë¥¼ ì„ í˜¸í•©ë‹ˆë‹¤. ë©´ì ‘ì—ì„œ ì ê·¹ì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê³  ë³¸ì¸ì˜ ìƒê°ì„ í‘œí˜„í•˜ì„¸ìš”.",
                    "author": "ë‚´ë¶€ì§ì›C",
                    "likes": 89,
                    "date": "2024-08-28"
                },
                {
                    "id": 4,
                    "category": "ì§€ì› ì „ëµ",
                    "title": "í¬íŠ¸í´ë¦¬ì˜¤ ì¤€ë¹„",
                    "content": "ê¹ƒí—ˆë¸Œì— ì •ë¦¬ëœ í”„ë¡œì íŠ¸ê°€ ìˆë‹¤ë©´ í° ì¥ì ì´ ë©ë‹ˆë‹¤. README íŒŒì¼ì— í”„ë¡œì íŠ¸ ê°œìš”, ê¸°ìˆ  ìŠ¤íƒ, êµ¬í˜„ ê³¼ì •ì„ ìƒì„¸íˆ ì‘ì„±í•˜ì„¸ìš”.",
                    "author": "í•©ê²©ìD",
                    "likes": 167,
                    "date": "2024-08-20"
                }
            ],
            "message": f"{company_name} ì§€ì› ê¿€íŒ ì •ë³´"
        }

    def get_job_detail(self, job_url):
        """ê³µê³  ìƒì„¸ ì •ë³´ ë°˜í™˜ (ìƒ˜í”Œ ë°ì´í„°)"""
        return {
            "success": True,
            "job_detail": {
                "company_name": "ìƒ˜í”Œ íšŒì‚¬",
                "job_title": "ë°±ì—”ë“œ ê°œë°œì",
                "job_type": "ì •ê·œì§",
                "location": "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬",
                "career_level": "ê²½ë ¥ 3-5ë…„",
                "education": "ëŒ€í•™êµ ì¡¸ì—…",
                "job_description": "Java/Spring ê¸°ë°˜ ë°±ì—”ë“œ ì‹œìŠ¤í…œ ê°œë°œ ë° ìš´ì˜",
                "requirements": "Java, Spring Boot, MySQL ê²½í—˜ í•„ìˆ˜",
                "preferred_qualifications": "AWS, Docker, Kubernetes ê²½í—˜ ìš°ëŒ€",
                "apply_url": "https://company-career.com/apply",
                "deadline": "D-7",
                "salary": "4000-6000ë§Œì›",
                "benefits": "4ëŒ€ë³´í—˜, í‡´ì§ê¸ˆ, ì—°ì°¨, êµìœ¡ë¹„ ì§€ì›",
                "full_content": "<div>ìƒì„¸í•œ ì±„ìš©ê³µê³  ë‚´ìš©...</div>"
            },
            "message": "ê³µê³  ìƒì„¸ ì •ë³´ (ìƒ˜í”Œ ë°ì´í„°)"
        }

    def close_driver(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()

# ì „ì—­ ìŠ¤í¬ë˜í¼ ì¸ìŠ¤í„´ìŠ¤
scraper = CatchScraper()

def _handle_api_error(e):
    """API ì—ëŸ¬ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜"""
    return jsonify({"success": False, "message": str(e)})

@app.route('/api/init', methods=['POST'])
def init_scraper():
    """ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”"""
    try:
        success = scraper.init_driver()
        return jsonify({
            "success": success,
            "message": "ìŠ¤í¬ë˜í¼ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤." if success else "ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        })
    except Exception as e:
        return _handle_api_error(e)

@app.route('/api/login', methods=['POST'])
def login():
    """ë¡œê·¸ì¸"""
    try:
        data = request.get_json()
        username = data.get('username', 'test0137')
        password = data.get('password', '#test0808')

        return jsonify(scraper.login(username, password))
    except Exception as e:
        return _handle_api_error(e)

@app.route('/api/status', methods=['GET'])
def get_status():
    """í˜„ì¬ ìƒíƒœ í™•ì¸"""
    try:
        return jsonify(scraper.get_current_status())
    except Exception as e:
        return _handle_api_error(e)

@app.route('/api/search-company-info', methods=['POST'])
def search_company_info():
    """ê¸°ì—… ê²€ìƒ‰ ë° ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
    try:
        data = request.get_json()
        company_name = data.get('company_name', '')

        if not company_name:
            return jsonify({"success": False, "message": "ê¸°ì—…ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})

        result = scraper.search_company_info(company_name)
        return jsonify(result)

    except Exception as e:
        return _handle_api_error(e)

@app.route('/api/job-essays', methods=['POST'])
def get_job_essays():
    """í•©ê²© ìì†Œì„œ ì •ë³´"""
    try:
        data = request.get_json()
        company_name = data.get('company_name', '')
        job_position = data.get('job_position', None)

        if not company_name:
            return jsonify({"success": False, "message": "ê¸°ì—…ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})

        result = scraper.get_job_essays(company_name, job_position)
        return jsonify(result)

    except Exception as e:
        return _handle_api_error(e)

@app.route('/api/job-tips', methods=['POST'])
def get_job_tips():
    """ì§€ì› ê¿€íŒ ì •ë³´"""
    try:
        data = request.get_json()
        company_name = data.get('company_name', '')
        job_position = data.get('job_position', None)

        if not company_name:
            return jsonify({"success": False, "message": "ê¸°ì—…ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})

        result = scraper.get_job_tips(company_name, job_position)
        return jsonify(result)

    except Exception as e:
        return _handle_api_error(e)

@app.route('/api/job-detail', methods=['POST'])
def get_job_detail():
    """ê³µê³  ìƒì„¸ ì •ë³´"""
    try:
        data = request.get_json()
        job_url = data.get('job_url', '')

        if not job_url:
            return jsonify({"success": False, "message": "ê³µê³  URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”."})

        result = scraper.get_job_detail(job_url)
        return jsonify(result)

    except Exception as e:
        return _handle_api_error(e)

@app.route('/health', methods=['GET'])
def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return jsonify({
        "status": "ok",
        "service": "Catch Scraper Service",
        "message": "ìºì¹˜ ì±„ìš© ì •ë³´ ìˆ˜ì§‘ ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤."
    })

if __name__ == '__main__':
    try:
        print("ğŸš€ Catch Scraper Service starting...")
        print("ğŸ“Š Available endpoints:")
        print("   - POST /api/init (Initialize)")
        print("   - POST /api/login (Login)")
        print("   - POST /api/search-company-info (Company Info)")
        print("   - POST /api/job-essays (Job Essays)")
        print("   - POST /api/job-tips (Job Tips)")
        print("   - POST /api/job-detail (Job Detail)")
        print("   - GET /health (Health Check)")
        app.run(host='0.0.0.0', port=3000, debug=True)
    except KeyboardInterrupt:
        scraper.close_driver()